
```
lab install do0012l ; lab start manage-navigate
```

---
# Overview della Console

Il focus principale di questa sezione Ã¨ la Search, diamo perÃ² una panoramica veloce sulle altre voci di menu che useremo negli step successivi

Certo ğŸ™‚
Ecco una **versione ancora piÃ¹ sintetica**, pensata come **commento rapidissimo davanti alla console** (3â€“4 minuti totali).

---

# RHACM â€“ Tour rapido menu **Infrastructure**

> *â€œInfrastructure Ã¨ il menu dove RHACM gestisce **cluster, host e risorse**, non solo policy.â€*

---

## 1ï¸âƒ£ **Clusters**

### **Cluster list**

* Tutti i cluster hub e managed
* Stato, versione, salute
* Aspetto importante: ci sono i links alle console del singolo cluster

### **Cluster sets**

* Raggruppamenti **logici** di cluster
* Usati per multi-tenancy, permessi, policy

### **Cluster pools**

* un insieme di cluster pre-installati
* pronti per essere assegnati on-demand

### **Discovered clusters**

* Cluster trovati ma **non ancora importati**
* Punto di ingresso per cluster esistenti

---

## 2ï¸âƒ£ **Automation templates**

* Template di automazione (es. Ansible)
* Usati per operazioni Day-2 e remediation

---

## 3ï¸âƒ£ **Host inventory**

* host bare metal
* host scoperti via Assisted Installer

---

## 4ï¸âƒ£ **Virtual machines**

* Gestione VM tramite OpenShift Virtualization
* Vista unificata VM + container

---

## ğŸ”‘ Chiusura

> *â€œInfrastructure Ã¨ il livello **operativo** di RHACM:
> dallâ€™host, al cluster, fino allâ€™automazione.â€*

Se vuoi, posso ridurla ancora in **30 secondi tipo elevator pitch**, oppure adattarla a un **pubblico Telco / Edge**.


## Script di lezione â€“ RHACM Search (con console aperta)

> *â€œAdesso spostiamoci su una delle funzionalitÃ  piÃ¹ sottovalutate ma piÃ¹ potenti di RHACM: la Search.â€*

### Introduzione dalla console

Guardate il menu di sinistra della console RHACM: clicco su **Search**.

Questa non Ã¨ una search â€œda kubectlâ€, e non Ã¨ neanche una search limitata a un singolo cluster.
Qui stiamo interrogando **tutta la fleet di cluster** gestiti da RHACM usando **un indice centralizzato** che conosce **oggetti e relazioni** di tutti i cluster.

Per prima cosa notate che la ricerca ha un campo di testo per la ricerca ma anche delle search selezionate perchÃ¨ frequenti. Ad esempio posso selezionare i Pod unhealthy.

Se clicco sui Pod unhealthy notiamo due cose:

1) in alto si Ã¨ popolata la Search con degli argomenti
2) in basso abbiamo il risultato ed anche le "related resources". Questo Ã¨ importante perchÃ¨ molto spesso se vogliamo intervenire non lo facciamo direttamente sul Pod ma sulla risorsa che lo controlla


Ora clicco sul Pod e lo apro lo YAML.

Questo Ã¨ importante: **La Search non Ã¨ solo read-only**
Da qui potete:

* ispezionare
* **modificare direttamente lo YAML**

Ovviamente con tutti i rischi del caso, soprattutto in ambienti GitOps.

Adesso proviamo noi ad inserire una chiave di ricerca custom. Ad esempio voglio vedere i deployment di mysql che sono nel namespace manage-navigate.

Inserisco nella search:

kind:Deployment namespace:manage-navigate name:mysqldb

clicchiamo sulla freccia ->

Questo ad esempio Ã¨ un Deploy che ha un problema. Nel laboratorio che segue andremo a fare troubleshooting di questo Deploy che ha un problema con lo storage. Se andiamo in edit della YAML vediamo che c'Ã¨ un claim che non esiste. Il claim corretto Ã¨:

 kind:PersistentVolumeClaim namespace:manage-navigate

 clicchiamo sulla freccia ->

### Indicizzazione:

Torniamo alla barra di ricerca. E cancelliamo la ricerca.
Notate, che in partenza mi vengono proposte delle chiavi come "cluster, kind, label"

Questo non sono solo suggerimenti, solo le chiavi indicizzate nel DB. Per cui se volete
delle search efficienti, andrete ad usare queste chiavi

Es: Scrivo:

```
label:application=mysqldb
```

PoichÃ¨ noi giÃ¹ usiamo le labels per diversi scopi in openshift, usarle anche per la search Ã¨ una best practice


 

Alcuni filtri supportano anche confronti numerici, ad esempio:



```
kind:Deployment replicas>=3
```

Questo Ã¨ estremamente utile per:

* audit
* capacity review
* troubleshooting trasversale


### Spiegazione architettura

Visto come funziona l'interfaccia utente, vediamo cosa succede "sotto il cofano" quando parte una Ricerca. 

Apri ACM_search.html

A sinistra abbiamo un Managed Cluster (uno dei tanti cluster della flotta) e a destra l'Hub Cluster, dove risiede l'intelligenza centrale."

Fase 1: Collector & Ingestion (Linee Blu)

(Mentre le particelle blu si muovono verso l'Indexer)

"Il processo inizia con i Collector.
Come vedete, ne abbiamo uno in ogni cluster della flotta (Deployed nell'addon search-collector) e uno anche nell'Hub stesso.
Il loro compito Ã¨ usare le API di Kubernetes per raccogliere informazioni su tutti gli oggetti (Pod, Nodi, PVC, ecc.) e calcolarne le relazioni.
Una volta raccolti, questi dati vengono inviati centralmente verso il componente Indexer che si trova sull'Hub."

Fase 2: Indexing & Storage (Linee Viola)

(Quando l'Indexer invia la particella al Database)

"L'Indexer riceve questo flusso continuo di dati da tutti i cluster.
Il suo ruolo Ã¨ processare queste informazioni e scriverle nel Database PostgreSQL persistente.
Qui Ã¨ dove viene mantenuto lo stato globale di tutta la nostra infrastruttura. Ora il database Ã¨ aggiornato e pronto per essere interrogato."

Fase 3: Search Request & RBAC (Linee Arancioni e Verdi)

(Quando parte la richiesta dall'Utente)

"Ora vediamo cosa succede quando un Utente (l'icona a destra) vuole cercare qualcosa nella console.
L'utente invia una richiesta alla Search API.
Attenzione a questo passaggio critico: l'API non si limita a chiedere i dati al DB. Prima esegue un controllo RBAC (Role-Based Access Control).
Verifica, cluster per cluster, se l'utente ha effettivamente il permesso di vedere quelle risorse.

Solo dopo aver validato i permessi, l'API interroga il Database, recupera i risultati e li restituisce all'utente, garantendo che nessuno veda dati per cui non Ã¨ autorizzato."

 

##  Database della Search RHACM

> *â€œAdesso vediamo dove materialmente la Search salva i suoi dati. I pods come abbiamo visto sono sull' Hub centrale e nello specifico nel namespace **open-cluster-management**

Apriamo il **Local Cluster** e prendiamo i Pods del namespace open-cluster-management:


Quello che vedete Ã¨ il **pod PostgreSQL** usato dalla Search

---

### 1ï¸âƒ£ Che tipo di database Ã¨?

Partiamo dallâ€™essenziale.

Qui abbiamo:

* **PostgreSQL 16**
* immagine ufficiale Red Hat (`registry.redhat.io/rhel8/postgresql-16`)
* usato **esclusivamente come database di indexing** per la Search

Questo database:

* **non Ã¨ applicativo**
* serve solo a memorizzare gli **indici degli oggetti Kubernetes** raccolti dai collector

Se lo perdo:

* **non perdo le applicazioni**
* ma **perdo lâ€™indice della Search**, che dovrÃ  essere ricostruito

---

### 2ï¸âƒ£ Il punto chiave: dove sono i dati?

Ora guardiamo **la parte piÃ¹ importante di tutto lo YAML**.

Nel container:

```yaml
volumeMounts:
  - name: postgresdb
    mountPath: /var/lib/pgsql/data
```

Questa Ã¨ **la directory dei dati di PostgreSQL**.

Ora andiamo a vedere **che volume Ã¨ `postgresdb`**:

```yaml
volumes:
  - name: postgresdb
    emptyDir: {}
```

ğŸ“Œ **Questo Ã¨ il punto didattico fondamentale**.

ğŸ‘‰ Il database usa **EmptyDir** come storage.

---

### 3ï¸âƒ£ Cosa significa EmptyDir, in pratica?

Spiegato senza giri di parole agli studenti:

* `emptyDir` vive **sul nodo**
* esiste **finchÃ© il pod esiste**
* se il pod viene:

  * riavviato
  * rischedulato
  * spostato su un altro nodo

ğŸ‘‰ **i dati vengono persi**

Questo Ã¨ **perfettamente accettabile in un laboratorio**, perchÃ©:

* pochi cluster
* pochi oggetti
* la Search si ricostruisce in pochi minuti

Ma Ã¨ **assolutamente non accettabile in produzione**.

---

### 4ï¸âƒ£ PerchÃ© Red Hat lo fa di default?

Domanda che qualcuno farÃ  sempre.

La risposta Ã¨: **scelta intenzionale**.

Per default RHACM privilegia:

* semplicitÃ 
* installazione rapida
* zero prerequisiti di storage

In altre parole:

> *â€œOut of the box, la Search funziona ovunque.â€*

Poi sta a **chi gestisce la piattaforma** renderla robusta.

---

### 5ï¸âƒ£ Segnali che lo storage non Ã¨ adeguato

Con questo setup, in ambienti grandi vedrete:

* Search lenta
* query che impiegano molti secondi
* ricostruzione completa dellâ€™indice dopo restart
* database che cresce ma Ã¨ limitato al filesystem del nodo

E infatti notate che:

```yaml
resources:
  limits:
    memory: 4Gi
```

Il database Ã¨ giÃ  configurato per usare **molta RAM**, proprio per compensare la mancanza di uno storage persistente.

---

### 6ï¸âƒ£ Come dice la documentazione di renderlo robusto

Andiamo a vedere sul bookshelf. 
ğŸ‘‰ **per ambienti medio-grandi, bisogna usare un PVC**

E questo **non si fa modificando il Pod**, ma la risorsa **Search** gestita dallâ€™operatore.

Esempio concettuale:

```yaml
apiVersion: search.open-cluster-management.io/v1alpha1
kind: Search
metadata:
  name: search-v2-operator
  namespace: open-cluster-management
spec:
  dbStorage:
    size: 10Gi
    storageClassName: fastdisk
```

Cosa succede a questo punto?

* Lâ€™operatore:

  * smette di usare `emptyDir`
  * crea un **PersistentVolumeClaim**
  * collega PostgreSQL a storage persistente

ğŸ‘‰ Il pod puÃ² morire, ma **i dati restano**

---
 

---

## ğŸ”Ÿ Come inquadrare RHACM Search mentalmente

Non pensarla come:

> â€œuna search UIâ€

Pensala come:

* **inventario globale**
* **motore di correlazione**
* **strumento di governance**
* **supporto a SRE e audit**

---

 
